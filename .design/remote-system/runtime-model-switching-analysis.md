# ëŸ°íƒ€ì„ ëª¨ë¸ ì „í™˜ ê¸°ëŠ¥ ë¶„ì„: Provider ì„¤ê³„ ì¬ê²€í† 

## ğŸ” í˜„ì¬ ëŸ°íƒ€ì„ ëª¨ë¸ ì „í™˜ ë©”ì»¤ë‹ˆì¦˜ ë¶„ì„

### **í•µì‹¬ ë°œê²¬: setModel() ë™ì‘ ë°©ì‹** ğŸ¯

#### **1. setModel() êµ¬í˜„ ë°©ì‹**
```typescript
// robota.ts - setModel ë©”ì„œë“œ
setModel(modelConfig: {
    provider: string;
    model: string;
    temperature?: number;
    maxTokens?: number;
    topP?: number;
    systemMessage?: string;
}): void {
    // 1. Provider ìœ íš¨ì„± ê²€ì‚¬
    const availableProviders = this.aiProviders.getProviderNames();
    if (!availableProviders.includes(modelConfig.provider)) {
        throw new ConfigurationError(`AI Provider '${modelConfig.provider}' not found`);
    }

    // 2. AIProviders Managerì— í˜„ì¬ Provider ì„¤ì •
    this.aiProviders.setCurrentProvider(modelConfig.provider, modelConfig.model);

    // 3. config.defaultModel ì—…ë°ì´íŠ¸
    this.config = {
        ...this.config,
        defaultModel: {
            ...this.config.defaultModel,
            provider: modelConfig.provider,
            model: modelConfig.model,
            // ìƒˆë¡œìš´ ëª¨ë¸ ì„¤ì •ìœ¼ë¡œ ì—…ë°ì´íŠ¸
            ...(modelConfig.temperature !== undefined && { temperature: modelConfig.temperature }),
            ...(modelConfig.maxTokens !== undefined && { maxTokens: modelConfig.maxTokens }),
            ...(modelConfig.topP !== undefined && { topP: modelConfig.topP }),
            ...(modelConfig.systemMessage !== undefined && { systemMessage: modelConfig.systemMessage })
        }
    };
}
```

#### **2. AIProviders Managerì˜ ì—­í• **
```typescript
// ai-provider-manager.ts
export class AIProviders {
    private providers = new Map<string, AIProvider>();
    private currentProvider: string | undefined;
    private currentModel: string | undefined;

    setCurrentProvider(name: string, model: string): void {
        // Provider ì¡´ì¬ í™•ì¸ë§Œ í•˜ê³ 
        const provider = this.providers.get(name);
        if (!provider) {
            throw new ConfigurationError(`Provider "${name}" is not registered`);
        }

        // í˜„ì¬ Providerì™€ Model ì´ë¦„ë§Œ ì €ì¥
        this.currentProvider = name;
        this.currentModel = model;
    }

    getCurrentProviderInstance(): AIProvider | undefined {
        // í˜„ì¬ ì„¤ì •ëœ Provider ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
        return this.currentProvider ? this.providers.get(this.currentProvider) : undefined;
    }
}
```

#### **3. ExecutionServiceì—ì„œ ì‹¤ì œ ì‚¬ìš©**
```typescript
// execution-service.ts
const provider = this.aiProviders.getCurrentProviderInstance();

// config.defaultModelì˜ ì„¤ì •ì„ ChatOptionsë¡œ ì „ë‹¬
const chatOptions: ChatOptions = {
    model: config.defaultModel.model,           // setModelë¡œ ì—…ë°ì´íŠ¸ëœ ëª¨ë¸
    ...(config.defaultModel.maxTokens !== undefined && { maxTokens: config.defaultModel.maxTokens }),
    ...(config.defaultModel.temperature !== undefined && { temperature: config.defaultModel.temperature }),
    ...(availableTools.length > 0 && { tools: availableTools })
};

// Providerì— ChatOptions ì „ë‹¬
const response = await provider.chat(conversationMessages, chatOptions);
```

## ğŸš¨ **ì¤‘ìš”í•œ ê¹¨ë‹¬ìŒ: ì™œ Provider ëª¨ë¸ ì„¤ì •ì´ ë¬´ì˜ë¯¸í•œê°€**

### **í˜„ì¬ ì•„í‚¤í…ì²˜ì˜ í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜** ğŸ”‘

#### **1. ProviderëŠ” ëª¨ë¸ ì„¤ì •ì„ ë³´ì§€ ì•ŠìŒ**
```typescript
// Provider ìƒì„±ì‹œ ì„¤ì •
const openaiProvider = new OpenAIProvider({
    client: openaiClient,
    model: 'gpt-3.5-turbo',     // ğŸ”´ ì´ ì„¤ì •ì€ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ!
    temperature: 0.5             // ğŸ”´ ì´ ì„¤ì •ë„ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ!
});

// ì‹¤ì œ chat í˜¸ì¶œì‹œ
await provider.chat(messages, {
    model: 'gpt-4',             // âœ… ì‹¤ì œë¡œ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ (defaultModelì—ì„œ)
    temperature: 0.8            // âœ… ì‹¤ì œë¡œ ì‚¬ìš©ë˜ëŠ” ì˜¨ë„ (defaultModelì—ì„œ)
});
```

#### **2. Providerì˜ chat() ë©”ì„œë“œê°€ ChatOptionsë¥¼ ìš°ì„  ì‚¬ìš©**
```typescript
// ëª¨ë“  Providerê°€ ì´ëŸ° íŒ¨í„´
export class OpenAIProvider extends BaseAIProvider {
    async chat(messages: UniversalMessage[], options?: ChatOptions): Promise<UniversalMessage> {
        const requestParams = {
            model: options?.model || 'gpt-4',           // ChatOptions ìš°ì„ !
            messages: messages,
            ...(options?.temperature !== undefined && { temperature: options.temperature }),
            ...(options?.maxTokens && { max_tokens: options.maxTokens })
        };
        
        return await this.client.chat.completions.create(requestParams);
    }
}
```

#### **3. ëŸ°íƒ€ì„ ëª¨ë¸ ì „í™˜ì˜ ì‹¤ì œ ë™ì‘**
```typescript
// ì´ˆê¸° ì„¤ì •
const robota = new Robota({
    aiProviders: [
        new OpenAIProvider({ client, model: 'gpt-3.5-turbo' }),    // ë¬´ì‹œë¨
        new AnthropicProvider({ client, model: 'claude-3-haiku' }) // ë¬´ì‹œë¨
    ],
    defaultModel: { provider: 'openai', model: 'gpt-4' }          // ì‹¤ì œ ì‚¬ìš©ë¨
});

// ëŸ°íƒ€ì„ ì „í™˜
robota.setModel({ provider: 'anthropic', model: 'claude-3-opus' });

// ë‹¤ìŒ ì‹¤í–‰ì‹œ
await robota.run('Hello'); 
// â†’ AnthropicProvider.chat(messages, { model: 'claude-3-opus' })
// â†’ Provider ìƒì„±ì‹œ ì„¤ì •í•œ 'claude-3-haiku'ëŠ” ì™„ì „íˆ ë¬´ì‹œë¨!
```

## ğŸ’¡ **Provider ëª¨ë¸ ì„¤ì •ì´ í•„ìš” ì—†ëŠ” ì´ìœ **

### **1. ì™„ì „í•œ ëŸ°íƒ€ì„ ì œì–´** ğŸ®
- **ëª¨ë“  ëª¨ë¸ ì„¤ì •ì´ ChatOptionsë¡œ ì „ë‹¬**ë¨
- **Provider ìƒì„±ì‹œ ì„¤ì •ì€ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ**
- **setModel()ë¡œ ì–¸ì œë“ ì§€ ë³€ê²½ ê°€ëŠ¥**

### **2. ë‹¤ì¤‘ Provider ì§€ì›** ğŸ”„
```typescript
// í•˜ë‚˜ì˜ Provider ì¸ìŠ¤í„´ìŠ¤ë¡œ ì—¬ëŸ¬ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥
const openaiProvider = new OpenAIProvider({ client });

// ëŸ°íƒ€ì„ì— ë‹¤ì–‘í•œ ëª¨ë¸ ì‚¬ìš©
await openaiProvider.chat(messages, { model: 'gpt-3.5-turbo' });
await openaiProvider.chat(messages, { model: 'gpt-4' });
await openaiProvider.chat(messages, { model: 'gpt-4-turbo' });
```

### **3. Providerë³„ ë…ë¦½ì  ëª¨ë¸ ì „í™˜** ğŸš€
```typescript
const robota = new Robota({
    aiProviders: [openaiProvider, anthropicProvider],
    defaultModel: { provider: 'openai', model: 'gpt-4' }
});

// OpenAI ëª¨ë¸ ì „í™˜
robota.setModel({ provider: 'openai', model: 'gpt-3.5-turbo' });

// Anthropicìœ¼ë¡œ Provider + ëª¨ë¸ ì „í™˜
robota.setModel({ provider: 'anthropic', model: 'claude-3-opus' });

// ë‹¤ì‹œ OpenAIì˜ ë‹¤ë¥¸ ëª¨ë¸ë¡œ
robota.setModel({ provider: 'openai', model: 'gpt-4-turbo' });
```

## ğŸ¯ **ê²°ë¡ : Provider ëª¨ë¸ ì„¤ì • ì œê±°ê°€ ë§ë‹¤**

### **ì™œ ë³µì¡í•˜ì§€ ì•Šì€ê°€?** âœ…

#### **1. ì´ë¯¸ ì™„ë²½í•œ ë©”ì»¤ë‹ˆì¦˜ ì¡´ì¬**
- `setModel()` â†’ `config.defaultModel` ì—…ë°ì´íŠ¸
- `ExecutionService` â†’ `ChatOptions`ë¡œ ì „ë‹¬
- `Provider.chat()` â†’ `ChatOptions` ìš°ì„  ì‚¬ìš©

#### **2. ProviderëŠ” ë‹¨ìˆœí•œ ì‹¤í–‰ê¸°**
```typescript
// Providerì˜ ì‹¤ì œ ì—­í• 
export class OpenAIProvider {
    constructor(options: { apiKey: string }) {
        // ì—°ê²° ì„¤ì •ë§Œ
    }
    
    async chat(messages, options) {
        // options.model, options.temperature ë“±ì„ ì‚¬ìš©í•´ì„œ ì‹¤í–‰
        return await this.client.chat.completions.create({
            model: options.model,        // ëŸ°íƒ€ì„ì— ì „ë‹¬ë°›ì€ ëª¨ë¸
            temperature: options.temperature,
            messages: messages
        });
    }
}
```

#### **3. ëª¨ë¸ ì „í™˜ì´ ë” ê°„ë‹¨í•´ì§**
```typescript
// âŒ ë³µì¡í•œ ë°©ì‹ (Providerë³„ ëª¨ë¸ ì„¤ì •)
const gpt35Provider = new OpenAIProvider({ model: 'gpt-3.5-turbo' });
const gpt4Provider = new OpenAIProvider({ model: 'gpt-4' });

const robota = new Robota({
    aiProviders: [gpt35Provider, gpt4Provider],
    defaultModel: { provider: '???', model: '???' }  // ì–´ë–»ê²Œ ë§¤í•‘?
});

// âœ… ê°„ë‹¨í•œ ë°©ì‹ (ëŸ°íƒ€ì„ ì „í™˜)
const openaiProvider = new OpenAIProvider({ apiKey: 'sk-...' });

const robota = new Robota({
    aiProviders: [openaiProvider],
    defaultModel: { provider: 'openai', model: 'gpt-4' }
});

robota.setModel({ provider: 'openai', model: 'gpt-3.5-turbo' }); // ê°„ë‹¨!
```

## ğŸš€ **ìµœì í™”ëœ ì„¤ê³„ í™•ì •**

### **Provider ì¸í„°í˜ì´ìŠ¤ ê°„ì†Œí™”**
```typescript
// âœ… ìµœì¢… ì„¤ê³„
export interface OpenAIProviderOptions {
    apiKey?: string;                    // LocalExecutorìš©
    executor?: ExecutorInterface;       // RemoteExecutorìš©
    
    // Provider ê³ ìœ  ì„¤ì •ë§Œ
    organization?: string;
    baseURL?: string;
    timeout?: number;
    responseFormat?: 'text' | 'json_object';
    
    // ğŸ”´ ì œê±°: ëª¨ë¸ ê´€ë ¨ ì„¤ì • (ëŸ°íƒ€ì„ì— ChatOptionsë¡œ ì²˜ë¦¬)
    // model?: string;
    // temperature?: number;
    // maxTokens?: number;
}
```

### **Robota ì¸í„°í˜ì´ìŠ¤ ìœ ì§€**
```typescript
// âœ… defaultModel ìœ ì§€ (ëŸ°íƒ€ì„ ì „í™˜ì˜ í•µì‹¬)
export interface AgentConfig {
    name: string;
    aiProviders: AIProvider[];
    defaultModel: {                     // âœ… í•„ìˆ˜: ëŸ°íƒ€ì„ ì „í™˜ì˜ ê¸°ì¤€ì 
        provider: string;
        model: string;
        temperature?: number;
        maxTokens?: number;
        topP?: number;
        systemMessage?: string;
    };
}
```

### **ì™„ë²½í•œ ëŸ°íƒ€ì„ ì „í™˜**
```typescript
// âœ… ìµœì¢… ì‚¬ìš©ë²•
const robota = new Robota({
    name: 'Assistant',
    aiProviders: [
        new OpenAIProvider({ apiKey: 'sk-...' }),       // ëª¨ë¸ ì„¤ì • ì—†ìŒ
        new AnthropicProvider({ apiKey: 'sk-ant-...' }), // ëª¨ë¸ ì„¤ì • ì—†ìŒ
        new GoogleProvider({ apiKey: 'AI...' })          // ëª¨ë¸ ì„¤ì • ì—†ìŒ
    ],
    defaultModel: {                                      // ìœ ì¼í•œ ëª¨ë¸ ì„¤ì •
        provider: 'openai',
        model: 'gpt-4',
        temperature: 0.7
    }
});

// ëŸ°íƒ€ì„ ì „í™˜ (ì™„ë²½í•˜ê²Œ ì‘ë™)
robota.setModel({ provider: 'anthropic', model: 'claude-3-opus', temperature: 0.9 });
robota.setModel({ provider: 'google', model: 'gemini-pro', temperature: 0.6 });
robota.setModel({ provider: 'openai', model: 'gpt-3.5-turbo', temperature: 0.8 });
```

## ğŸ‰ **ìµœì¢… ê²€ì¦: ëŸ°íƒ€ì„ ì „í™˜ì´ ë” ê°„ë‹¨í•´ì§**

### **í˜„ì¬ ë°©ì‹ (ë³µì¡í•¨)** âŒ
```typescript
// Providerë³„ë¡œ ëª¨ë¸ ì„¤ì • â†’ defaultModelê³¼ ì¤‘ë³µ â†’ í˜¼ë€
const openaiProvider = new OpenAIProvider({ model: 'gpt-3.5-turbo' });
const robota = new Robota({
    aiProviders: [openaiProvider],
    defaultModel: { provider: 'openai', model: 'gpt-4' } // ì¶©ëŒ!
});
```

### **ì œì•ˆ ë°©ì‹ (ê°„ë‹¨í•¨)** âœ…
```typescript
// ProviderëŠ” ì—°ê²°ë§Œ, ëª¨ë¸ì€ ëŸ°íƒ€ì„ì— â†’ ëª…í™•í•¨
const openaiProvider = new OpenAIProvider({ apiKey: 'sk-...' });
const robota = new Robota({
    aiProviders: [openaiProvider],
    defaultModel: { provider: 'openai', model: 'gpt-4' } // ëª…í™•!
});

// ëŸ°íƒ€ì„ ì „í™˜ë„ ì§ê´€ì 
robota.setModel({ provider: 'openai', model: 'gpt-3.5-turbo' });
```

**ê²°ë¡ : Provider ëª¨ë¸ ì„¤ì • ì œê±°ê°€ ëŸ°íƒ€ì„ ëª¨ë¸ ì „í™˜ì„ ë” ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤!** ğŸ¯ 