<!-- 
 ⚠️  AUTO-GENERATED FILE - DO NOT EDIT MANUALLY
 This file is automatically generated by scripts/docs-generator.js
 To make changes, edit the source TypeScript files or update the generator script
-->

[core](../../) / [Exports](../modules) / OpenAIProvider

# Class: OpenAIProvider

OpenAI Provider wrapper
Wraps OpenAI client with unified AIProvider interface.

## Implements

- [`AIProvider`](../interfaces/AIProvider)

## Table of contents

### Constructors

- [constructor](OpenAIProvider#constructor)

### Properties

- [name](OpenAIProvider#name)

### Methods

- [chat](OpenAIProvider#chat)
- [chatStream](OpenAIProvider#chatstream)
- [close](OpenAIProvider#close)

## Constructors

### constructor

• **new OpenAIProvider**(`client`): [`OpenAIProvider`](OpenAIProvider)

#### Parameters

| Name | Type |
| :------ | :------ |
| `client` | `any` |

#### Returns

[`OpenAIProvider`](OpenAIProvider)

#### Defined in

[providers/openai-provider.ts:13](https://github.com/woojubb/robota/blob/f2044536073df65f9112d45570cc110d351b585d/packages/core/src/providers/openai-provider.ts#L13)

## Properties

### name

• `Readonly` **name**: ``"openai"``

Provider name

#### Implementation of

[AIProvider](../interfaces/AIProvider).[name](../interfaces/AIProvider#name)

#### Defined in

[providers/openai-provider.ts:9](https://github.com/woojubb/robota/blob/f2044536073df65f9112d45570cc110d351b585d/packages/core/src/providers/openai-provider.ts#L9)

## Methods

### chat

▸ **chat**(`model`, `context`, `options?`): `Promise`\<[`ModelResponse`](../interfaces/ModelResponse)\>

Chat request

#### Parameters

| Name | Type |
| :------ | :------ |
| `model` | `string` |
| `context` | [`Context`](../interfaces/Context) |
| `options?` | `any` |

#### Returns

`Promise`\<[`ModelResponse`](../interfaces/ModelResponse)\>

#### Implementation of

[AIProvider](../interfaces/AIProvider).[chat](../interfaces/AIProvider#chat)

#### Defined in

[providers/openai-provider.ts:20](https://github.com/woojubb/robota/blob/f2044536073df65f9112d45570cc110d351b585d/packages/core/src/providers/openai-provider.ts#L20)

___

### chatStream

▸ **chatStream**(`model`, `context`, `options?`): `AsyncGenerator`\<[`StreamingResponseChunk`](../interfaces/StreamingResponseChunk), `void`, `unknown`\>

Streaming chat request

#### Parameters

| Name | Type |
| :------ | :------ |
| `model` | `string` |
| `context` | [`Context`](../interfaces/Context) |
| `options?` | `any` |

#### Returns

`AsyncGenerator`\<[`StreamingResponseChunk`](../interfaces/StreamingResponseChunk), `void`, `unknown`\>

#### Implementation of

[AIProvider](../interfaces/AIProvider).[chatStream](../interfaces/AIProvider#chatstream)

#### Defined in

[providers/openai-provider.ts:94](https://github.com/woojubb/robota/blob/f2044536073df65f9112d45570cc110d351b585d/packages/core/src/providers/openai-provider.ts#L94)

___

### close

▸ **close**(): `Promise`\<`void`\>

Release resources

#### Returns

`Promise`\<`void`\>

#### Implementation of

[AIProvider](../interfaces/AIProvider).[close](../interfaces/AIProvider#close)

#### Defined in

[providers/openai-provider.ts:161](https://github.com/woojubb/robota/blob/f2044536073df65f9112d45570cc110d351b585d/packages/core/src/providers/openai-provider.ts#L161)
