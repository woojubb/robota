<!-- 
 ⚠️  AUTO-GENERATED FILE - DO NOT EDIT MANUALLY
 This file is automatically generated by scripts/docs-generator.js
 To make changes, edit the source TypeScript files or update the generator script
-->

[openai](../../) / [Exports](../modules) / ChatOptions

# Interface: ChatOptions

Chat options for AI provider requests

## Table of contents

### Properties

- [tools](ChatOptions#tools)
- [maxTokens](ChatOptions#maxtokens)
- [temperature](ChatOptions#temperature)
- [model](ChatOptions#model)

## Properties

### tools

• `Optional` **tools**: `ToolSchema`[]

Tool schemas to provide to the AI provider

#### Defined in

[openai/src/provider.ts:15](https://github.com/woojubb/robota/blob/d84cd2e1e6915e9f7e9aff8f9b06df02e55c139b/packages/openai/src/provider.ts#L15)

___

### maxTokens

• `Optional` **maxTokens**: `number`

Maximum number of tokens to generate

#### Defined in

[openai/src/provider.ts:17](https://github.com/woojubb/robota/blob/d84cd2e1e6915e9f7e9aff8f9b06df02e55c139b/packages/openai/src/provider.ts#L17)

___

### temperature

• `Optional` **temperature**: `number`

Temperature for response randomness (0-1)

#### Defined in

[openai/src/provider.ts:19](https://github.com/woojubb/robota/blob/d84cd2e1e6915e9f7e9aff8f9b06df02e55c139b/packages/openai/src/provider.ts#L19)

___

### model

• `Optional` **model**: `string`

Model to use for the request

#### Defined in

[openai/src/provider.ts:21](https://github.com/woojubb/robota/blob/d84cd2e1e6915e9f7e9aff8f9b06df02e55c139b/packages/openai/src/provider.ts#L21)
