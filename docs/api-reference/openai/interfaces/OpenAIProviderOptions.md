<!-- 
 ⚠️  AUTO-GENERATED FILE - DO NOT EDIT MANUALLY
 This file is automatically generated by scripts/docs-generator.js
 To make changes, edit the source TypeScript files or update the generator script
-->

[openai](../../) / [Exports](../modules) / OpenAIProviderOptions

# Interface: OpenAIProviderOptions

OpenAI provider options

## Hierarchy

- `ProviderOptions`

  ↳ **`OpenAIProviderOptions`**

## Table of contents

### Properties

- [stopSequences](OpenAIProviderOptions#stopsequences)
- [streamMode](OpenAIProviderOptions#streammode)
- [enableParallelToolCalls](OpenAIProviderOptions#enableparalleltoolcalls)
- [maxConcurrentToolCalls](OpenAIProviderOptions#maxconcurrenttoolcalls)
- [toolCallDelayMs](OpenAIProviderOptions#toolcalldelayms)
- [model](OpenAIProviderOptions#model)
- [temperature](OpenAIProviderOptions#temperature)
- [maxTokens](OpenAIProviderOptions#maxtokens)
- [apiKey](OpenAIProviderOptions#apikey)
- [organization](OpenAIProviderOptions#organization)
- [timeout](OpenAIProviderOptions#timeout)
- [baseURL](OpenAIProviderOptions#baseurl)
- [responseFormat](OpenAIProviderOptions#responseformat)
- [jsonSchema](OpenAIProviderOptions#jsonschema)
- [client](OpenAIProviderOptions#client)
- [enablePayloadLogging](OpenAIProviderOptions#enablepayloadlogging)
- [payloadLogDir](OpenAIProviderOptions#payloadlogdir)
- [includeTimestampInLogFiles](OpenAIProviderOptions#includetimestampinlogfiles)

## Properties

### stopSequences

• `Optional` **stopSequences**: `string`[]

#### Inherited from

ProviderOptions.stopSequences

#### Defined in

core/dist/index.d.ts:11

___

### streamMode

• `Optional` **streamMode**: `boolean`

#### Inherited from

ProviderOptions.streamMode

#### Defined in

core/dist/index.d.ts:12

___

### enableParallelToolCalls

• `Optional` **enableParallelToolCalls**: `boolean`

Enable parallel execution of tool calls within a single AI response.
When true, multiple tool calls in the same response are executed concurrently.
When false, tool calls are executed sequentially (original behavior).

**`Default Value`**

```ts
true
```

#### Inherited from

ProviderOptions.enableParallelToolCalls

#### Defined in

core/dist/index.d.ts:20

___

### maxConcurrentToolCalls

• `Optional` **maxConcurrentToolCalls**: `number`

Maximum number of tool calls to execute concurrently.
Helps prevent overwhelming APIs with too many simultaneous requests.

**`Default Value`**

```ts
3
```

#### Inherited from

ProviderOptions.maxConcurrentToolCalls

#### Defined in

core/dist/index.d.ts:27

___

### toolCallDelayMs

• `Optional` **toolCallDelayMs**: `number`

Delay in milliseconds between starting each tool call to avoid rate limits.
Applied when executing tool calls in parallel to space out API requests.

**`Default Value`**

```ts
100
```

#### Inherited from

ProviderOptions.toolCallDelayMs

#### Defined in

core/dist/index.d.ts:34

___

### model

• **model**: `string`

Model name to use (default: gpt-3.5-turbo)

#### Overrides

ProviderOptions.model

#### Defined in

[openai/src/types.ts:11](https://github.com/woojubb/robota/blob/a3ab9410e815223c52230ddc246f82f91b3bd0b7/packages/openai/src/types.ts#L11)

___

### temperature

• `Optional` **temperature**: `number`

Temperature (0~1)

#### Overrides

ProviderOptions.temperature

#### Defined in

[openai/src/types.ts:16](https://github.com/woojubb/robota/blob/a3ab9410e815223c52230ddc246f82f91b3bd0b7/packages/openai/src/types.ts#L16)

___

### maxTokens

• `Optional` **maxTokens**: `number`

Maximum number of tokens

#### Overrides

ProviderOptions.maxTokens

#### Defined in

[openai/src/types.ts:21](https://github.com/woojubb/robota/blob/a3ab9410e815223c52230ddc246f82f91b3bd0b7/packages/openai/src/types.ts#L21)

___

### apiKey

• `Optional` **apiKey**: `string`

OpenAI API key (optional: not required when using client)

#### Defined in

[openai/src/types.ts:26](https://github.com/woojubb/robota/blob/a3ab9410e815223c52230ddc246f82f91b3bd0b7/packages/openai/src/types.ts#L26)

___

### organization

• `Optional` **organization**: `string`

OpenAI organization ID (optional)

#### Defined in

[openai/src/types.ts:31](https://github.com/woojubb/robota/blob/a3ab9410e815223c52230ddc246f82f91b3bd0b7/packages/openai/src/types.ts#L31)

___

### timeout

• `Optional` **timeout**: `number`

API request timeout (milliseconds)

#### Defined in

[openai/src/types.ts:36](https://github.com/woojubb/robota/blob/a3ab9410e815223c52230ddc246f82f91b3bd0b7/packages/openai/src/types.ts#L36)

___

### baseURL

• `Optional` **baseURL**: `string`

API base URL (default: 'https://api.openai.com/v1')

#### Defined in

[openai/src/types.ts:41](https://github.com/woojubb/robota/blob/a3ab9410e815223c52230ddc246f82f91b3bd0b7/packages/openai/src/types.ts#L41)

___

### responseFormat

• `Optional` **responseFormat**: ``"text"`` \| ``"json_object"`` \| ``"json_schema"``

Response format (default: 'text')
- 'text': Plain text response
- 'json_object': Legacy JSON mode (requires system message)
- 'json_schema': Structured Outputs with schema validation

#### Defined in

[openai/src/types.ts:49](https://github.com/woojubb/robota/blob/a3ab9410e815223c52230ddc246f82f91b3bd0b7/packages/openai/src/types.ts#L49)

___

### jsonSchema

• `Optional` **jsonSchema**: `Object`

JSON schema for structured outputs (required when responseFormat is 'json_schema')

#### Type declaration

| Name | Type |
| :------ | :------ |
| `name` | `string` |
| `description?` | `string` |
| `schema?` | `Record`\<`string`, `unknown`\> |
| `strict?` | `boolean` |

#### Defined in

[openai/src/types.ts:54](https://github.com/woojubb/robota/blob/a3ab9410e815223c52230ddc246f82f91b3bd0b7/packages/openai/src/types.ts#L54)

___

### client

• **client**: `OpenAI`

OpenAI client instance (required)

#### Defined in

[openai/src/types.ts:64](https://github.com/woojubb/robota/blob/a3ab9410e815223c52230ddc246f82f91b3bd0b7/packages/openai/src/types.ts#L64)

___

### enablePayloadLogging

• `Optional` **enablePayloadLogging**: `boolean`

Enable API payload logging to files
When enabled, saves API request payloads to log files

**`Default Value`**

```ts
false
```

#### Defined in

[openai/src/types.ts:72](https://github.com/woojubb/robota/blob/a3ab9410e815223c52230ddc246f82f91b3bd0b7/packages/openai/src/types.ts#L72)

___

### payloadLogDir

• `Optional` **payloadLogDir**: `string`

Directory path for storing API payload log files

**`Default Value`**

```ts
'./logs/api-payloads'
```

#### Defined in

[openai/src/types.ts:79](https://github.com/woojubb/robota/blob/a3ab9410e815223c52230ddc246f82f91b3bd0b7/packages/openai/src/types.ts#L79)

___

### includeTimestampInLogFiles

• `Optional` **includeTimestampInLogFiles**: `boolean`

Include timestamp in payload log filenames

**`Default Value`**

```ts
true
```

#### Defined in

[openai/src/types.ts:86](https://github.com/woojubb/robota/blob/a3ab9410e815223c52230ddc246f82f91b3bd0b7/packages/openai/src/types.ts#L86)
