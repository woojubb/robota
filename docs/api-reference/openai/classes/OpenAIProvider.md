<!-- 
 ⚠️  AUTO-GENERATED FILE - DO NOT EDIT MANUALLY
 This file is automatically generated by scripts/docs-generator.js
 To make changes, edit the source TypeScript files or update the generator script
-->

[OpenAI API](../../) / [Exports](../modules) / OpenAIProvider

# Class: OpenAIProvider

OpenAI provider implementation

Implements the AIProvider interface to integrate with Robota.

## Implements

- `AIProvider`

## Table of contents

### Constructors

- [constructor](OpenAIProvider#constructor)

### Properties

- [instance](OpenAIProvider#instance)
- [name](OpenAIProvider#name)
- [options](OpenAIProvider#options)
- [type](OpenAIProvider#type)

### Methods

- [chat](OpenAIProvider#chat)
- [chatStream](OpenAIProvider#chatstream)
- [close](OpenAIProvider#close)
- [formatFunctions](OpenAIProvider#formatfunctions)
- [formatMessages](OpenAIProvider#formatmessages)
- [parseResponse](OpenAIProvider#parseresponse)
- [parseStreamingChunk](OpenAIProvider#parsestreamingchunk)

## Constructors

### constructor

• **new OpenAIProvider**(`options`): [`OpenAIProvider`](OpenAIProvider)

#### Parameters

| Name | Type |
| :------ | :------ |
| `options` | [`OpenAIProviderOptions`](../interfaces/OpenAIProviderOptions) |

#### Returns

[`OpenAIProvider`](OpenAIProvider)

#### Defined in

[openai/src/provider.ts:46](https://github.com/woojubb/robota/blob/4f21f71cc775c491f2f7e354b7e5fc2c2396f413/packages/openai/src/provider.ts#L46)

## Properties

### instance

• **instance**: `OpenAI`

Client instance

#### Defined in

[openai/src/provider.ts:39](https://github.com/woojubb/robota/blob/4f21f71cc775c491f2f7e354b7e5fc2c2396f413/packages/openai/src/provider.ts#L39)

___

### name

• **name**: `string` = `'openai'`

Provider name

#### Implementation of

AIProvider.name

#### Defined in

[openai/src/provider.ts:24](https://github.com/woojubb/robota/blob/4f21f71cc775c491f2f7e354b7e5fc2c2396f413/packages/openai/src/provider.ts#L24)

___

### options

• **options**: [`OpenAIProviderOptions`](../interfaces/OpenAIProviderOptions)

Provider options

#### Defined in

[openai/src/provider.ts:44](https://github.com/woojubb/robota/blob/4f21f71cc775c491f2f7e354b7e5fc2c2396f413/packages/openai/src/provider.ts#L44)

___

### type

• **type**: `string` = `'openai'`

Client type

#### Defined in

[openai/src/provider.ts:34](https://github.com/woojubb/robota/blob/4f21f71cc775c491f2f7e354b7e5fc2c2396f413/packages/openai/src/provider.ts#L34)

## Methods

### chat

▸ **chat**(`model`, `context`, `options?`): `Promise`\<`ModelResponse`\>

Model chat request

#### Parameters

| Name | Type |
| :------ | :------ |
| `model` | `string` |
| `context` | `Context` |
| `options?` | `any` |

#### Returns

`Promise`\<`ModelResponse`\>

#### Implementation of

AIProvider.chat

#### Defined in

[openai/src/provider.ts:189](https://github.com/woojubb/robota/blob/4f21f71cc775c491f2f7e354b7e5fc2c2396f413/packages/openai/src/provider.ts#L189)

___

### chatStream

▸ **chatStream**(`model`, `context`, `options?`): `AsyncGenerator`\<`StreamingResponseChunk`, `void`, `unknown`\>

Model chat streaming request

#### Parameters

| Name | Type |
| :------ | :------ |
| `model` | `string` |
| `context` | `Context` |
| `options?` | `any` |

#### Returns

`AsyncGenerator`\<`StreamingResponseChunk`, `void`, `unknown`\>

#### Implementation of

AIProvider.chatStream

#### Defined in

[openai/src/provider.ts:255](https://github.com/woojubb/robota/blob/4f21f71cc775c491f2f7e354b7e5fc2c2396f413/packages/openai/src/provider.ts#L255)

___

### close

▸ **close**(): `Promise`\<`void`\>

Release resources (if needed)

#### Returns

`Promise`\<`void`\>

#### Implementation of

AIProvider.close

#### Defined in

[openai/src/provider.ts:329](https://github.com/woojubb/robota/blob/4f21f71cc775c491f2f7e354b7e5fc2c2396f413/packages/openai/src/provider.ts#L329)

___

### formatFunctions

▸ **formatFunctions**(`functions`): `ChatCompletionTool`[]

Convert function definitions to OpenAI format

#### Parameters

| Name | Type |
| :------ | :------ |
| `functions` | `FunctionDefinition`[] |

#### Returns

`ChatCompletionTool`[]

#### Defined in

[openai/src/provider.ts:123](https://github.com/woojubb/robota/blob/4f21f71cc775c491f2f7e354b7e5fc2c2396f413/packages/openai/src/provider.ts#L123)

___

### formatMessages

▸ **formatMessages**(`messages`): `ChatCompletionMessageParam`[]

Convert messages to OpenAI format

#### Parameters

| Name | Type |
| :------ | :------ |
| `messages` | `Message`[] |

#### Returns

`ChatCompletionMessageParam`[]

**`Deprecated`**

Use OpenAIConversationAdapter.toOpenAIFormat instead

#### Defined in

[openai/src/provider.ts:66](https://github.com/woojubb/robota/blob/4f21f71cc775c491f2f7e354b7e5fc2c2396f413/packages/openai/src/provider.ts#L66)

___

### parseResponse

▸ **parseResponse**(`response`): `ModelResponse`

Convert OpenAI API response to standard format

#### Parameters

| Name | Type |
| :------ | :------ |
| `response` | `ChatCompletion` |

#### Returns

`ModelResponse`

#### Defined in

[openai/src/provider.ts:137](https://github.com/woojubb/robota/blob/4f21f71cc775c491f2f7e354b7e5fc2c2396f413/packages/openai/src/provider.ts#L137)

___

### parseStreamingChunk

▸ **parseStreamingChunk**(`chunk`): `StreamingResponseChunk`

Convert streaming response chunk to standard format

#### Parameters

| Name | Type |
| :------ | :------ |
| `chunk` | `ChatCompletionChunk` |

#### Returns

`StreamingResponseChunk`

#### Defined in

[openai/src/provider.ts:167](https://github.com/woojubb/robota/blob/4f21f71cc775c491f2f7e354b7e5fc2c2396f413/packages/openai/src/provider.ts#L167)
