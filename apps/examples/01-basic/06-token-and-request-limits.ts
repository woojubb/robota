/**
 * 06-token-and-request-limits.ts
 * 
 * ì´ ì˜ˆì œëŠ” Robotaì˜ í† í° ë° ìš”ì²­ ì œí•œ ê¸°ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤:
 * - ê¸°ë³¸ ì œí•œ ì„¤ì • (maxTokens: 4096, maxRequests: 25)
 * - ì»¤ìŠ¤í…€ ì œí•œ ì„¤ì •
 * - ë¬´ì œí•œ ì„¤ì • (0 ê°’ ì‚¬ìš©)
 * - ì‚¬ì „ í† í° ê³„ì‚°ì„ í†µí•œ ë¹„ìš© ì ˆì•½
 * - ì œí•œ ì´ˆê³¼ ì‹œ ì—ëŸ¬ ì²˜ë¦¬
 * - ì‹¤ì‹œê°„ ì œí•œ ì •ë³´ ëª¨ë‹ˆí„°ë§
 * - ì• ë„ë¦¬í‹±ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
 */

import { Robota, OpenAIProvider } from '@robota-sdk/core';
import OpenAI from 'openai';
import dotenv from 'dotenv';

// í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
dotenv.config();

async function main() {
    // API í‚¤ ê²€ì¦
    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
        throw new Error('OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤');
    }

    // OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    const openaiClient = new OpenAI({
        apiKey
    });

    // OpenAI Provider ìƒì„±
    const openaiProvider = new OpenAIProvider(openaiClient);

    console.log('ğŸš€ Robota í† í° ë° ìš”ì²­ ì œí•œ ê¸°ëŠ¥ ì˜ˆì œ\n');

    // 1. ê¸°ë³¸ ì œí•œ ì„¤ì • ì˜ˆì œ
    await demonstrateDefaultLimits(openaiProvider);

    // 2. ì»¤ìŠ¤í…€ ì œí•œ ì„¤ì • ì˜ˆì œ
    await demonstrateCustomLimits(openaiProvider);

    // 3. ë¬´ì œí•œ ì„¤ì • ì˜ˆì œ
    await demonstrateUnlimitedMode(openaiProvider);

    // 4. ì‚¬ì „ í† í° ê³„ì‚°ì„ í†µí•œ ë¹„ìš© ì ˆì•½ ì˜ˆì œ
    await demonstrateTokenPrevention(openaiProvider);

    // 5. ìš”ì²­ ì œí•œ ì˜ˆì œ
    await demonstrateRequestLimits(openaiProvider);

    // 6. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ
    await demonstrateRealTimeMonitoring(openaiProvider);

    console.log('\nâœ… ëª¨ë“  ì˜ˆì œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!');
}

async function demonstrateDefaultLimits(openaiProvider: OpenAIProvider) {
    console.log('=== 1. ê¸°ë³¸ ì œí•œ ì„¤ì • ì˜ˆì œ ===');

    // ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ Robota ìƒì„± (maxTokens: 4096, maxRequests: 25)
    const robota = new Robota({
        aiProviders: { 'openai': openaiProvider },
        currentProvider: 'openai',
        currentModel: 'gpt-3.5-turbo',
        systemPrompt: 'ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.'
    });

    // ê¸°ë³¸ ì œí•œ í™•ì¸
    console.log(`ê¸°ë³¸ í† í° ì œí•œ: ${robota.getMaxTokenLimit()}`);
    console.log(`ê¸°ë³¸ ìš”ì²­ ì œí•œ: ${robota.getMaxRequestLimit()}`);

    // ì œí•œ ì •ë³´ ì¶œë ¥
    const limitInfo = robota.getLimitInfo();
    console.log('í˜„ì¬ ì œí•œ ìƒíƒœ:', {
        maxTokens: limitInfo.maxTokens,
        maxRequests: limitInfo.maxRequests,
        remainingTokens: limitInfo.remainingTokens,
        remainingRequests: limitInfo.remainingRequests,
        isTokensUnlimited: limitInfo.isTokensUnlimited,
        isRequestsUnlimited: limitInfo.isRequestsUnlimited
    });

    // ëª‡ ê°œì˜ ìš”ì²­ ì‹¤í–‰
    const response = await robota.execute('íƒ€ì…ìŠ¤í¬ë¦½íŠ¸ë€ ë¬´ì—‡ì¸ê°€ìš”?');
    console.log(`ì‘ë‹µ: ${response.substring(0, 100)}...`);

    // ì‚¬ìš©ëŸ‰ í™•ì¸
    console.log(`ì‚¬ìš©ëœ í† í°: ${robota.getTotalTokensUsed()}`);
    console.log(`ì‹¤í–‰ëœ ìš”ì²­: ${robota.getRequestCount()}\n`);
}

async function demonstrateCustomLimits(openaiProvider: OpenAIProvider) {
    console.log('=== 2. ì»¤ìŠ¤í…€ ì œí•œ ì„¤ì • ì˜ˆì œ ===');

    // ë‚®ì€ ì œí•œìœ¼ë¡œ ì„¤ì •
    const robota = new Robota({
        aiProviders: { 'openai': openaiProvider },
        currentProvider: 'openai',
        currentModel: 'gpt-3.5-turbo',
        systemPrompt: 'ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.',
        maxTokenLimit: 200,  // ë§¤ìš° ë‚®ì€ í† í° ì œí•œ
        maxRequestLimit: 3   // 3íšŒ ìš”ì²­ë§Œ í—ˆìš©
    });

    console.log(`ì„¤ì •ëœ í† í° ì œí•œ: ${robota.getMaxTokenLimit()}`);
    console.log(`ì„¤ì •ëœ ìš”ì²­ ì œí•œ: ${robota.getMaxRequestLimit()}`);

    try {
        // ì²« ë²ˆì§¸ ìš”ì²­
        const response1 = await robota.execute('ì•ˆë…•í•˜ì„¸ìš”');
        console.log(`1ë²ˆì§¸ ìš”ì²­ ì„±ê³µ: ${response1.substring(0, 50)}...`);

        // ë‘ ë²ˆì§¸ ìš”ì²­
        const response2 = await robota.execute('ë‚ ì”¨ëŠ” ì–´ë•Œìš”?');
        console.log(`2ë²ˆì§¸ ìš”ì²­ ì„±ê³µ: ${response2.substring(0, 50)}...`);

        // ì„¸ ë²ˆì§¸ ìš”ì²­ (í† í° ì œí•œì— ê±¸ë¦´ ìˆ˜ ìˆìŒ)
        const response3 = await robota.execute('í”„ë¡œê·¸ë˜ë°ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.');
        console.log(`3ë²ˆì§¸ ìš”ì²­ ì„±ê³µ: ${response3.substring(0, 50)}...`);

    } catch (error) {
        console.log(`ì œí•œ ì´ˆê³¼ ì—ëŸ¬: ${(error as Error).message}`);
    }

    console.log(`ìµœì¢… í† í° ì‚¬ìš©ëŸ‰: ${robota.getTotalTokensUsed()}`);
    console.log(`ìµœì¢… ìš”ì²­ ìˆ˜: ${robota.getRequestCount()}\n`);
}

async function demonstrateUnlimitedMode(openaiProvider: OpenAIProvider) {
    console.log('=== 3. ë¬´ì œí•œ ì„¤ì • ì˜ˆì œ ===');

    // ë¬´ì œí•œ ì„¤ì • (0 ê°’ ì‚¬ìš©)
    const robota = new Robota({
        aiProviders: { 'openai': openaiProvider },
        currentProvider: 'openai',
        currentModel: 'gpt-3.5-turbo',
        systemPrompt: 'ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.',
        maxTokenLimit: 0,    // ë¬´ì œí•œ
        maxRequestLimit: 0   // ë¬´ì œí•œ
    });

    const limitInfo = robota.getLimitInfo();
    console.log('ë¬´ì œí•œ ëª¨ë“œ í™•ì¸:');
    console.log(`í† í° ë¬´ì œí•œ: ${limitInfo.isTokensUnlimited}`);
    console.log(`ìš”ì²­ ë¬´ì œí•œ: ${limitInfo.isRequestsUnlimited}`);
    console.log(`ë‚¨ì€ í† í°: ${limitInfo.remainingTokens ?? 'ë¬´ì œí•œ'}`);
    console.log(`ë‚¨ì€ ìš”ì²­: ${limitInfo.remainingRequests ?? 'ë¬´ì œí•œ'}`);

    // ë¬´ì œí•œ ëª¨ë“œì—ì„œëŠ” ë§ì€ ìš”ì²­ë„ ê°€ëŠ¥
    const response = await robota.execute('íƒ€ì…ìŠ¤í¬ë¦½íŠ¸ì˜ ì¥ì ì„ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.');
    console.log(`ì‘ë‹µ: ${response.substring(0, 100)}...`);
    console.log(`í† í° ì‚¬ìš©ëŸ‰: ${robota.getTotalTokensUsed()}\n`);
}

async function demonstrateTokenPrevention(openaiProvider: OpenAIProvider) {
    console.log('=== 4. ì‚¬ì „ í† í° ê³„ì‚°ì„ í†µí•œ ë¹„ìš© ì ˆì•½ ì˜ˆì œ ===');

    // ë§¤ìš° ë‚®ì€ í† í° ì œí•œ ì„¤ì •
    const robota = new Robota({
        aiProviders: { 'openai': openaiProvider },
        currentProvider: 'openai',
        currentModel: 'gpt-3.5-turbo',
        systemPrompt: 'ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.',
        maxTokenLimit: 50,   // ë§¤ìš° ë‚®ì€ ì œí•œ
        debug: true          // ë””ë²„ê·¸ ëª¨ë“œë¡œ í† í° ê³„ì‚° ê³¼ì • í™•ì¸
    });

    console.log(`ë§¤ìš° ë‚®ì€ í† í° ì œí•œ ì„¤ì •: ${robota.getMaxTokenLimit()}`);

    try {
        // ì§§ì€ ë©”ì‹œì§€ (ì„±ê³µí•  ê²ƒ)
        console.log('\nì§§ì€ ë©”ì‹œì§€ ì‹œë„...');
        const shortResponse = await robota.execute('ì•ˆë…•');
        console.log(`âœ… ì„±ê³µ: ${shortResponse}`);
        console.log(`ì‚¬ìš©ëœ í† í°: ${robota.getTotalTokensUsed()}`);

        // ê¸´ ë©”ì‹œì§€ (ì‚¬ì „ ê³„ì‚°ìœ¼ë¡œ ì°¨ë‹¨ë  ê²ƒ)
        console.log('\nê¸´ ë©”ì‹œì§€ ì‹œë„...');
        await robota.execute('íƒ€ì…ìŠ¤í¬ë¦½íŠ¸ì˜ ëª¨ë“  ê¸°ëŠ¥ê³¼ ì¥ì , ë‹¨ì , ê·¸ë¦¬ê³  ìë°”ìŠ¤í¬ë¦½íŠ¸ì™€ì˜ ì°¨ì´ì ì— ëŒ€í•´ ë§¤ìš° ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”. ë˜í•œ ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œ ì–´ë–»ê²Œ í™œìš©í•˜ëŠ”ì§€ì™€ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ë„ ì•Œë ¤ì£¼ì„¸ìš”.');

    } catch (error) {
        console.log(`âŒ ì‚¬ì „ í† í° ê³„ì‚°ìœ¼ë¡œ ìš”ì²­ ì°¨ë‹¨: ${(error as Error).message}`);
        console.log('ğŸ’° API ë¹„ìš© ì ˆì•½ ì„±ê³µ! ì‹¤ì œ API í˜¸ì¶œ ì—†ì´ ì œí•œ ì´ˆê³¼ë¥¼ ê°ì§€í–ˆìŠµë‹ˆë‹¤.');
    }

    console.log(`ìµœì¢… í† í° ì‚¬ìš©ëŸ‰: ${robota.getTotalTokensUsed()}\n`);
}

async function demonstrateRequestLimits(openaiProvider: OpenAIProvider) {
    console.log('=== 5. ìš”ì²­ ì œí•œ ì˜ˆì œ ===');

    // ìš”ì²­ ìˆ˜ ì œí•œ
    const robota = new Robota({
        aiProviders: { 'openai': openaiProvider },
        currentProvider: 'openai',
        currentModel: 'gpt-3.5-turbo',
        systemPrompt: 'ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.',
        maxTokenLimit: 5000,  // ì¶©ë¶„í•œ í† í°
        maxRequestLimit: 2    // ë‹¨ 2íšŒ ìš”ì²­ë§Œ í—ˆìš©
    });

    console.log(`ìš”ì²­ ì œí•œ: ${robota.getMaxRequestLimit()}íšŒ`);

    try {
        // ì²« ë²ˆì§¸ ìš”ì²­
        console.log('1ë²ˆì§¸ ìš”ì²­...');
        await robota.execute('ì•ˆë…•í•˜ì„¸ìš”');
        console.log(`âœ… 1ë²ˆì§¸ ìš”ì²­ ì„±ê³µ (ë‚¨ì€ ìš”ì²­: ${robota.getLimitInfo().remainingRequests})`);

        // ë‘ ë²ˆì§¸ ìš”ì²­
        console.log('2ë²ˆì§¸ ìš”ì²­...');
        await robota.execute('ê°ì‚¬í•©ë‹ˆë‹¤');
        console.log(`âœ… 2ë²ˆì§¸ ìš”ì²­ ì„±ê³µ (ë‚¨ì€ ìš”ì²­: ${robota.getLimitInfo().remainingRequests})`);

        // ì„¸ ë²ˆì§¸ ìš”ì²­ (ì œí•œ ì´ˆê³¼)
        console.log('3ë²ˆì§¸ ìš”ì²­...');
        await robota.execute('ë˜ ë‹¤ë¥¸ ì§ˆë¬¸');

    } catch (error) {
        console.log(`âŒ ìš”ì²­ ì œí•œ ì´ˆê³¼: ${(error as Error).message}`);
    }

    console.log(`ìµœì¢… ìš”ì²­ ìˆ˜: ${robota.getRequestCount()}\n`);
}

async function demonstrateRealTimeMonitoring(openaiProvider: OpenAIProvider) {
    console.log('=== 6. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ===');

    const robota = new Robota({
        aiProviders: { 'openai': openaiProvider },
        currentProvider: 'openai',
        currentModel: 'gpt-3.5-turbo',
        systemPrompt: 'ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.',
        maxTokenLimit: 500,
        maxRequestLimit: 5
    });

    // ëª¨ë‹ˆí„°ë§ í•¨ìˆ˜
    function printStatus(step: string) {
        const limitInfo = robota.getLimitInfo();
        const analytics = robota.getAnalytics();

        console.log(`\n[${step}] í˜„ì¬ ìƒíƒœ:`);
        console.log(`  í† í°: ${limitInfo.currentTokensUsed}/${limitInfo.maxTokens} (ë‚¨ì€: ${limitInfo.remainingTokens})`);
        console.log(`  ìš”ì²­: ${limitInfo.currentRequestCount}/${limitInfo.maxRequests} (ë‚¨ì€: ${limitInfo.remainingRequests})`);
        console.log(`  í‰ê·  í† í°/ìš”ì²­: ${analytics.averageTokensPerRequest.toFixed(1)}`);
    }

    printStatus('ì‹œì‘');

    // ì—¬ëŸ¬ ìš”ì²­ ì‹¤í–‰í•˜ë©° ëª¨ë‹ˆí„°ë§
    const questions = [
        'ì•ˆë…•í•˜ì„¸ìš”',
        'íƒ€ì…ìŠ¤í¬ë¦½íŠ¸ë€?',
        'ReactëŠ” ë¬´ì—‡ì¸ê°€ìš”?',
        'Node.js ì„¤ëª…'
    ];

    for (let i = 0; i < questions.length; i++) {
        try {
            console.log(`\nì§ˆë¬¸ ${i + 1}: "${questions[i]}"`);
            const response = await robota.execute(questions[i]);
            console.log(`ì‘ë‹µ: ${response.substring(0, 80)}...`);
            printStatus(`ìš”ì²­ ${i + 1} ì™„ë£Œ`);

        } catch (error) {
            console.log(`âŒ ìš”ì²­ ${i + 1} ì‹¤íŒ¨: ${(error as Error).message}`);
            break;
        }
    }

    // ìµœì¢… ì• ë„ë¦¬í‹±ìŠ¤
    const finalAnalytics = robota.getAnalytics();
    console.log('\nğŸ“Š ìµœì¢… ì• ë„ë¦¬í‹±ìŠ¤:');
    console.log(`  ì´ ìš”ì²­ ìˆ˜: ${finalAnalytics.requestCount}`);
    console.log(`  ì´ í† í° ì‚¬ìš©ëŸ‰: ${finalAnalytics.totalTokensUsed}`);
    console.log(`  í‰ê·  í† í°/ìš”ì²­: ${finalAnalytics.averageTokensPerRequest.toFixed(1)}`);

    // ì‹œê°„ëŒ€ë³„ ì‚¬ìš©ëŸ‰ (ìµœê·¼ 1ë¶„)
    const oneMinuteAgo = new Date(Date.now() - 60000);
    const recentUsage = robota.getTokenUsageByPeriod(oneMinuteAgo);
    console.log(`  ìµœê·¼ 1ë¶„ê°„: ${recentUsage.requestCount}ìš”ì²­, ${recentUsage.totalTokens}í† í°`);

    console.log('\n');
}

// ì‹¤í–‰
main().catch(error => {
    console.error('ì˜¤ë¥˜ ë°œìƒ:', error);
}); 